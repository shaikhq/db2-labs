{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Automating the Collection of EXPLAIN Plans and Runtime Metrics in Db2 LUW\n",
    "This notebook automates the process of running a SQL query in Db2 and capturing its execution details using EXPLAIN tables and activity event monitors. The workflow includes:\n",
    "\n",
    "1. **Setup of Activity Event Monitor:** Configures an event monitor in Db2 to collect runtime metrics such as execution time and resource usage during query execution.\n",
    "2. **Creation of EXPLAIN Tables:** Sets up EXPLAIN tables in Db2 to store detailed execution plans for SQL queries.\n",
    "3. **Query Execution:** Runs a SQL query to gather execution metrics and analyze its performance.\n",
    "4. **EXPLAIN Plan Generation:** Captures the execution plan of the query to understand how Db2 will process the operation.\n",
    "5. **Exporting Data:** Exports the collected EXPLAIN and activity monitor data as CSV files for external analysis or reporting.\n",
    "\n",
    "For detailed setup instructions and guidance on running this notebook, refer to the [README.md](./README.md) file in the same directory.\n",
    "\n",
    "This notebook provides a fully automated approach for analyzing query performance and gathering runtime metrics, helping database administrators and developers optimize their queries effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (These values will be overwritten when called by papermill)\n",
    "queryid = None\n",
    "sql_statement = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Db2 Magic Commands Notebook Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1708: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2305: SyntaxWarning: invalid escape sequence '\\?'\n",
      "/tmp/ipykernel_429051/2299624180.py:1708: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  firstCommand = \"(?:^\\s*)([a-zA-Z]+)(?:\\s+.*|$)\"\n",
      "/tmp/ipykernel_429051/2299624180.py:2305: SyntaxWarning: invalid escape sequence '\\?'\n",
      "  pattern = \"\\?\\*[0-9]+\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db2 Extensions Loaded. Version: 2024-09-16\n"
     ]
    }
   ],
   "source": [
    "# Enable Db2 Magic Commands Extensions for Jupyter Notebook\n",
    "if not os.path.isfile('db2.ipynb'):\n",
    "    os.system('wget https://raw.githubusercontent.com/IBM/db2-jupyter/master/db2.ipynb')\n",
    "%run db2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the top-level output directory\n",
    "top_level_dir = os.path.join(os.getcwd(), \"output\")\n",
    "\n",
    "# Create the top-level directory only if it doesn't exist\n",
    "os.makedirs(top_level_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful. tpcds @ localhost \n"
     ]
    }
   ],
   "source": [
    "db2creds = dotenv_values('.env')\n",
    "%sql CONNECT CREDENTIALS db2creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "# Activate event monitor\n",
    "%sql SET EVENT MONITOR ACTEVMON STATE 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, 'queryid1', None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set client info\n",
    "%sql CALL WLM_SET_CLIENT_INFO(NULL,NULL,NULL,:queryid,NULL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql {sql_statement}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "# Deactivate the event monitor to ensure its data is written to the activity tables\n",
    "%sql SET EVENT MONITOR ACTEVMON STATE 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql SELECT a.APPL_ID, a.UOW_ID, a.ACTIVITY_ID \\\n",
    "    FROM ACTIVITY_ACTEVMON a \\\n",
    "    WHERE a.ACTIVITY_TYPE = 'READ_DML' AND a.TPMON_ACC_STR = :queryid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_id = result['APPL_ID'].iloc[0]\n",
    "uow_id = result.at[0, 'UOW_ID'].item()\n",
    "activity_id = result.at[0, 'ACTIVITY_ID'].item()\n",
    "event_monitor = 'ACTEVMON'\n",
    "schema = 'DB2INST1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        APPL_ID  UOW_ID  ACTIVITY_ID\n",
      "0  127.0.0.1.36406.250225023906      77            1\n",
      "1  127.0.0.1.43592.250225031504       5            1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appl_id:  127.0.0.1.36406.250225023906\n",
      "uow_id:  77\n",
      "activity_id:  1\n"
     ]
    }
   ],
   "source": [
    "print('appl_id: ', appl_id)\n",
    "print('uow_id: ', uow_id)\n",
    "print('activity_id: ', activity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture explain_output\n",
    "sql = f'''\"CALL EXPLAIN_FROM_ACTIVITY('{appl_id}', '{uow_id}', '{activity_id}', '{event_monitor}', '{schema}', null, null, null, null, null)\"'''\n",
    "_ = ! db2 \"connect to TPCDS\" \n",
    "\n",
    "explain = %system db2 {sql}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLAIN_TIME: 2025-02-24-19.15.08.317428\n",
      "SOURCE_NAME: SYSSH200\n",
      "SOURCE_SCHEMA: NULLID\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "explain_time = None\n",
    "source_name = None\n",
    "source_schema = None\n",
    "\n",
    "# Iterate through the list\n",
    "for i in range(len(explain)):\n",
    "    if \"EXPLAIN_TIME\" in explain[i]:\n",
    "        explain_time = explain[i + 1].split(\":\")[-1].strip()\n",
    "    elif \"SOURCE_NAME\" in explain[i]:\n",
    "        source_name = explain[i + 1].split(\":\")[-1].strip()\n",
    "    elif \"SOURCE_SCHEMA\" in explain[i]:\n",
    "        source_schema = explain[i + 1].split(\":\")[-1].strip()\n",
    "\n",
    "# Print extracted values\n",
    "print(\"EXPLAIN_TIME:\", explain_time)\n",
    "print(\"SOURCE_NAME:\", source_name)\n",
    "print(\"SOURCE_SCHEMA:\", source_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-02-24-19.15.08.317428'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Name: tpcds\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "db2creds = dotenv_values('.env')\n",
    "\n",
    "# Extract the database name\n",
    "database_name = db2creds.get(\"database\")  # Use .get() to avoid KeyError if the key is missing\n",
    "\n",
    "# Print the extracted database name\n",
    "print(\"Database Name:\", database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Explain and Export the Explain output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db2exfmt -d \"tpcds\" -w \"2025-02-24-19.15.08.317428\" -n \"SYSSH200\" -s \"NULLID\" -# 0 -o \"/home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/explain.out\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DB2 Universal Database Version 11.5, 5622-044 (c) Copyright IBM Corp. 1991, 2019\n",
      "Licensed Material - Program Property of IBM\n",
      "IBM DATABASE 2 Explain Table Format Tool\n",
      "\n",
      "Connect to Database Successful.\n",
      "Output is in /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/explain.out.\n",
      "Executing Connect Reset -- Connect Reset was Successful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the Database.\n",
      "SQL statements have been loaded from sql_statements.json\n",
      "Processing table: ACTIVITYSTMT_ACTEVMON\n",
      "Saved ACTIVITYSTMT_ACTEVMON data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/ACTIVITYSTMT_ACTEVMON.csv\n",
      "Processing table: ACTIVITY_ACTEVMON\n",
      "Saved ACTIVITY_ACTEVMON data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/ACTIVITY_ACTEVMON.csv\n",
      "Processing table: EXPLAIN_ACTUALS\n",
      "Saved EXPLAIN_ACTUALS data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_ACTUALS.csv\n",
      "Processing table: EXPLAIN_INSTANCE\n",
      "Saved EXPLAIN_INSTANCE data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_INSTANCE.csv\n",
      "Processing table: EXPLAIN_OBJECT\n",
      "Saved EXPLAIN_OBJECT data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_OBJECT.csv\n",
      "Processing table: EXPLAIN_OPERATOR\n",
      "Saved EXPLAIN_OPERATOR data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_OPERATOR.csv\n",
      "Processing table: EXPLAIN_PREDICATE\n",
      "Saved EXPLAIN_PREDICATE data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_PREDICATE.csv\n",
      "Processing table: EXPLAIN_STATEMENT\n",
      "Saved EXPLAIN_STATEMENT data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_STATEMENT.csv\n",
      "Processing table: EXPLAIN_STREAM\n",
      "Saved EXPLAIN_STREAM data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-19.15.08.317428/EXPLAIN_STREAM.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the subdirectory for a specific explain_time output\n",
    "outputdir = os.path.join(top_level_dir, f\"{explain_time}\")\n",
    "os.makedirs(outputdir, exist_ok=True)  # Create the subdirectory if it doesn't exist\n",
    "\n",
    "# If the directory exists, delete its contents\n",
    "for filename in os.listdir(outputdir):\n",
    "    file_path = os.path.join(outputdir, filename)\n",
    "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)  # Remove files and symlinks\n",
    "    elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)  # Remove subdirectories\n",
    "\n",
    "# Define output file\n",
    "explain_output = \"explain.out\"\n",
    "\n",
    "db2exfmt_cmd = f'''db2exfmt -d \"{database_name}\" -w \"{explain_time}\" -n \"{source_name}\" -s \"{source_schema}\" -# 0 -o \"{outputdir}/{explain_output}\"'''\n",
    "print(db2exfmt_cmd)\n",
    "\n",
    "# Uncomment the following line to execute the command (if running in a shell environment)\n",
    "os.system(db2exfmt_cmd)\n",
    "\n",
    "# Load the dictionary from the JSON file\n",
    "with open(\"export_sql.json\", \"r\") as json_file:\n",
    "    export_sql_statements = json.load(json_file)\n",
    "\n",
    "print(\"SQL statements have been loaded from sql_statements.json\")\n",
    "\n",
    "# Loop through each table in the dictionary\n",
    "for table_name, query in export_sql_statements.items():\n",
    "    print(f\"Processing table: {table_name}\")\n",
    "\n",
    "    # Execute the dynamically generated SQL using %sql magic\n",
    "    df_result = %sql {query}\n",
    "\n",
    "    # Convert result to Pandas DataFrame\n",
    "    # df_result = df_result.DataFrame()\n",
    "\n",
    "    # Save to CSV without including the index in the \"explain\" directory\n",
    "    output_file_path = os.path.join(outputdir, f\"{table_name}.csv\")\n",
    "    df_result.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Saved {table_name} data to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "%sql CONNECT RESET"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
