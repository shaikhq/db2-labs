{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Automating the Collection of EXPLAIN Plans and Runtime Metrics in Db2 LUW\n",
    "This notebook automates the process of running a SQL query in Db2 and capturing its execution details using EXPLAIN tables and activity event monitors. The workflow includes:\n",
    "\n",
    "1. **Setup of Activity Event Monitor:** Configures an event monitor in Db2 to collect runtime metrics such as execution time and resource usage during query execution.\n",
    "2. **Creation of EXPLAIN Tables:** Sets up EXPLAIN tables in Db2 to store detailed execution plans for SQL queries.\n",
    "3. **Query Execution:** Runs a SQL query to gather execution metrics and analyze its performance.\n",
    "4. **EXPLAIN Plan Generation:** Captures the execution plan of the query to understand how Db2 will process the operation.\n",
    "5. **Exporting Data:** Exports the collected EXPLAIN and activity monitor data as CSV files for external analysis or reporting.\n",
    "\n",
    "For detailed setup instructions and guidance on running this notebook, refer to the [README.md](./README.md) file in the same directory.\n",
    "\n",
    "This notebook provides a fully automated approach for analyzing query performance and gathering runtime metrics, helping database administrators and developers optimize their queries effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show the full content in the 'sql' column\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width without truncation\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent DataFrame from wrapping across lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Enter the Filename of a List of SQL Queries - each query needs to be in a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input SQL file\n",
    "input_file = \"queries.sql\"  # Replace with your actual file name\n",
    "\n",
    "# Read the SQL queries from the file, skipping empty lines and removing ending semicolons\n",
    "with open(input_file, \"r\") as file:\n",
    "    sql_queries = [\n",
    "        line.strip().rstrip(';')  # Strip whitespace and remove trailing semicolons\n",
    "        for line in file\n",
    "        if line.strip()  # Skip empty lines\n",
    "    ]\n",
    "\n",
    "# Construct the DataFrame\n",
    "df_queries = pd.DataFrame({\n",
    "    \"queryid\": range(1, len(sql_queries) + 1),\n",
    "    \"sql\": sql_queries\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryid</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SELECT TPCDS.STORE_SALES.SS_WHOLESALE_COST , TPCDS.STORE_RETURNS.SR_NET_LOSS FROM TPCDS.STORE_SALES INNER JOIN TPCDS.STORE_RETURNS ON TPCDS.STORE_RETURNS.SR_TICKET_NUMBER = TPCDS.STORE_SALES.SS_TICKET_NUMBER AND TPCDS.STORE_RETURNS.SR_ITEM_SK = TPCDS.STORE_SALES.SS_ITEM_SK WHERE TPCDS.STORE_SALES.SS_STORE_SK = 2 AND TPCDS.STORE_RETURNS.SR_RETURNED_DATE_SK = 2451680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SELECT TPCDS.CATALOG_RETURNS.CR_RETURNING_ADDR_SK , TPCDS.CATALOG_SALES.CS_SALES_PRICE FROM TPCDS.CATALOG_RETURNS INNER JOIN TPCDS.CATALOG_SALES ON TPCDS.CATALOG_SALES.CS_ORDER_NUMBER = TPCDS.CATALOG_RETURNS.CR_ORDER_NUMBER AND TPCDS.CATALOG_SALES.CS_ITEM_SK = TPCDS.CATALOG_RETURNS.CR_ITEM_SK WHERE TPCDS.CATALOG_SALES.CS_NET_PAID &lt;= +00456.68 AND TPCDS.CATALOG_RETURNS.CR_REFUNDED_HDEMO_SK &lt;= 939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SELECT TPCDS.STORE_SALES.SS_EXT_LIST_PRICE , TPCDS.STORE_RETURNS.SR_STORE_CREDIT FROM TPCDS.STORE_SALES INNER JOIN TPCDS.STORE_RETURNS ON TPCDS.STORE_RETURNS.SR_CUSTOMER_SK = TPCDS.STORE_SALES.SS_CUSTOMER_SK AND TPCDS.STORE_RETURNS.SR_ITEM_SK = TPCDS.STORE_SALES.SS_ITEM_SK WHERE TPCDS.STORE_SALES.SS_ADDR_SK &gt;= 8970 AND TPCDS.STORE_RETURNS.SR_CUSTOMER_SK &lt;= 93014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SELECT SR_ADDR_SK, SR_CDEMO_SK, SR_RETURN_AMT, SR_RETURN_AMT_INC_TAX, SR_RETURN_TIME_SK, SR_REVERSED_CHARGE, SR_STORE_CREDIT, SS_EXT_DISCOUNT_AMT, SS_SOLD_DATE_SK, SS_LIST_PRICE, SS_QUANTITY, SS_SALES_PRICE, SS_SOLD_TIME_SK, SS_WHOLESALE_COST FROM TPCDS.STORE_RETURNS JOIN TPCDS.STORE_SALES ON SR_ITEM_SK = SS_ITEM_SK AND SR_CUSTOMER_SK = SS_CUSTOMER_SK AND SS_TICKET_NUMBER = SR_TICKET_NUMBER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   queryid                                                                                                                                                                                                                                                                                                                                                                                                             sql\n",
       "0        1                                 SELECT TPCDS.STORE_SALES.SS_WHOLESALE_COST , TPCDS.STORE_RETURNS.SR_NET_LOSS FROM TPCDS.STORE_SALES INNER JOIN TPCDS.STORE_RETURNS ON TPCDS.STORE_RETURNS.SR_TICKET_NUMBER = TPCDS.STORE_SALES.SS_TICKET_NUMBER AND TPCDS.STORE_RETURNS.SR_ITEM_SK = TPCDS.STORE_SALES.SS_ITEM_SK WHERE TPCDS.STORE_SALES.SS_STORE_SK = 2 AND TPCDS.STORE_RETURNS.SR_RETURNED_DATE_SK = 2451680\n",
       "1        2  SELECT TPCDS.CATALOG_RETURNS.CR_RETURNING_ADDR_SK , TPCDS.CATALOG_SALES.CS_SALES_PRICE FROM TPCDS.CATALOG_RETURNS INNER JOIN TPCDS.CATALOG_SALES ON TPCDS.CATALOG_SALES.CS_ORDER_NUMBER = TPCDS.CATALOG_RETURNS.CR_ORDER_NUMBER AND TPCDS.CATALOG_SALES.CS_ITEM_SK = TPCDS.CATALOG_RETURNS.CR_ITEM_SK WHERE TPCDS.CATALOG_SALES.CS_NET_PAID <= +00456.68 AND TPCDS.CATALOG_RETURNS.CR_REFUNDED_HDEMO_SK <= 939\n",
       "2        3                                    SELECT TPCDS.STORE_SALES.SS_EXT_LIST_PRICE , TPCDS.STORE_RETURNS.SR_STORE_CREDIT FROM TPCDS.STORE_SALES INNER JOIN TPCDS.STORE_RETURNS ON TPCDS.STORE_RETURNS.SR_CUSTOMER_SK = TPCDS.STORE_SALES.SS_CUSTOMER_SK AND TPCDS.STORE_RETURNS.SR_ITEM_SK = TPCDS.STORE_SALES.SS_ITEM_SK WHERE TPCDS.STORE_SALES.SS_ADDR_SK >= 8970 AND TPCDS.STORE_RETURNS.SR_CUSTOMER_SK <= 93014\n",
       "3        4       SELECT SR_ADDR_SK, SR_CDEMO_SK, SR_RETURN_AMT, SR_RETURN_AMT_INC_TAX, SR_RETURN_TIME_SK, SR_REVERSED_CHARGE, SR_STORE_CREDIT, SS_EXT_DISCOUNT_AMT, SS_SOLD_DATE_SK, SS_LIST_PRICE, SS_QUANTITY, SS_SALES_PRICE, SS_SOLD_TIME_SK, SS_WHOLESALE_COST FROM TPCDS.STORE_RETURNS JOIN TPCDS.STORE_SALES ON SR_ITEM_SK = SS_ITEM_SK AND SR_CUSTOMER_SK = SS_CUSTOMER_SK AND SS_TICKET_NUMBER = SR_TICKET_NUMBER"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the top-level output directory\n",
    "top_level_dir = os.path.join(os.getcwd(), \"output\")\n",
    "\n",
    "# If the top-level directory exists, delete it and recreate\n",
    "if os.path.exists(top_level_dir):\n",
    "    shutil.rmtree(top_level_dir)\n",
    "os.makedirs(top_level_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Db2 Magic Commands Notebook Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db2 Extensions Loaded. Version: 2024-09-16\n"
     ]
    }
   ],
   "source": [
    "# Enable Db2 Magic Commands Extensions for Jupyter Notebook\n",
    "if not os.path.isfile('db2.ipynb'):\n",
    "    os.system('wget https://raw.githubusercontent.com/IBM/db2-jupyter/master/db2.ipynb')\n",
    "%run db2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful. tpcds @ localhost \n"
     ]
    }
   ],
   "source": [
    "db2creds = dotenv_values('.env')\n",
    "%sql CONNECT CREDENTIALS db2creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CALL ADMIN_CMD(\"UPDATE DATABASE CONFIGURATION USING SECTION_ACTUALS BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Deactivate event monitor, `ACTEVMON`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "%sql SET EVENT MONITOR ACTEVMON STATE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Drop Existing Tables for event monitor `ACTEVMON`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -q\n",
    "DROP TABLE ACTIVITYMETRICS_ACTEVMON;\n",
    "DROP TABLE ACTIVITYSTMT_ACTEVMON;\n",
    "DROP TABLE ACTIVITYVALS_ACTEVMON;\n",
    "DROP TABLE ACTIVITY_ACTEVMON;\n",
    "DROP TABLE CONTROL_ACTEVMON;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Install Explain Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "CALL SYSINSTALLOBJECTS('EXPLAIN', 'D', NULL, 'DB2INST1');\n",
    "CALL SYSINSTALLOBJECTS('EXPLAIN', 'C', NULL, 'DB2INST1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Alter Workload to Collect Activity Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "%sql ALTER WORKLOAD SYSDEFAULTUSERWORKLOAD COLLECT ACTIVITY DATA ON ALL WITH DETAILS, SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Drop and re-create a New Event Monitor, `ACTEVMON`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "%%sql \n",
    "DROP EVENT MONITOR ACTEVMON;\n",
    "CREATE EVENT MONITOR ACTEVMON FOR ACTIVITIES WRITE TO TABLE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "# Activate event monitor\n",
    "%sql SET EVENT MONITOR ACTEVMON STATE 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, 'queryid1', None]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set client info\n",
    "%sql CALL WLM_SET_CLIENT_INFO(NULL,NULL,NULL,'queryid1',NULL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%sql -q\n",
    "SELECT STORE_SALES.SS_WHOLESALE_COST, STORE_RETURNS.SR_NET_LOSS\n",
    "FROM STORE_SALES\n",
    "INNER JOIN STORE_RETURNS\n",
    "ON STORE_RETURNS.SR_TICKET_NUMBER = STORE_SALES.SS_TICKET_NUMBER\n",
    "AND STORE_RETURNS.SR_ITEM_SK = STORE_SALES.SS_ITEM_SK\n",
    "WHERE STORE_SALES.SS_STORE_SK = 2\n",
    "AND STORE_RETURNS.SR_RETURNED_DATE_SK = 2451680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "# Deactivate the event monitor to ensure its data is written to the activity tables\n",
    "%sql SET EVENT MONITOR ACTEVMON STATE 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql SELECT a.APPL_ID, a.UOW_ID, a.ACTIVITY_ID \\\n",
    "    FROM ACTIVITY_ACTEVMON a \\\n",
    "    WHERE a.ACTIVITY_TYPE = 'READ_DML' AND a.TPMON_ACC_STR = 'queryid1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "appl_id = result['APPL_ID'].iloc[0]\n",
    "uow_id = result.at[0, 'UOW_ID'].item()\n",
    "activity_id = result.at[0, 'ACTIVITY_ID'].item()\n",
    "event_monitor = 'ACTEVMON'\n",
    "schema = 'DB2INST1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        APPL_ID  UOW_ID  ACTIVITY_ID\n",
      "0  127.0.0.1.36406.250225023906      77            1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appl_id:  127.0.0.1.36406.250225023906\n",
      "uow_id:  77\n",
      "activity_id:  1\n"
     ]
    }
   ],
   "source": [
    "print('appl_id: ', appl_id)\n",
    "print('uow_id: ', uow_id)\n",
    "print('activity_id: ', activity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture explain_output\n",
    "sql = f'''\"CALL EXPLAIN_FROM_ACTIVITY('{appl_id}', '{uow_id}', '{activity_id}', '{event_monitor}', '{schema}', null, null, null, null, null)\"'''\n",
    "_ = ! db2 \"connect to TPCDS\" \n",
    "\n",
    "explain = %system db2 {sql}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLAIN_TIME: 2025-02-24-18.39.39.920008\n",
      "SOURCE_NAME: SYSSH200\n",
      "SOURCE_SCHEMA: NULLID\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "explain_time = None\n",
    "source_name = None\n",
    "source_schema = None\n",
    "\n",
    "# Iterate through the list\n",
    "for i in range(len(explain)):\n",
    "    if \"EXPLAIN_TIME\" in explain[i]:\n",
    "        explain_time = explain[i + 1].split(\":\")[-1].strip()\n",
    "    elif \"SOURCE_NAME\" in explain[i]:\n",
    "        source_name = explain[i + 1].split(\":\")[-1].strip()\n",
    "    elif \"SOURCE_SCHEMA\" in explain[i]:\n",
    "        source_schema = explain[i + 1].split(\":\")[-1].strip()\n",
    "\n",
    "# Print extracted values\n",
    "print(\"EXPLAIN_TIME:\", explain_time)\n",
    "print(\"SOURCE_NAME:\", source_name)\n",
    "print(\"SOURCE_SCHEMA:\", source_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-02-24-18.39.39.920008'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Name: tpcds\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "db2creds = dotenv_values('.env')\n",
    "\n",
    "# Extract the database name\n",
    "database_name = db2creds.get(\"database\")  # Use .get() to avoid KeyError if the key is missing\n",
    "\n",
    "# Print the extracted database name\n",
    "print(\"Database Name:\", database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Explain and Export the Explain output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db2exfmt -d \"tpcds\" -w \"2025-02-24-18.39.39.920008\" -n \"SYSSH200\" -s \"NULLID\" -# 0 -o \"/home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/explain.out\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DB2 Universal Database Version 11.5, 5622-044 (c) Copyright IBM Corp. 1991, 2019\n",
      "Licensed Material - Program Property of IBM\n",
      "IBM DATABASE 2 Explain Table Format Tool\n",
      "\n",
      "Connect to Database Successful.\n",
      "Output is in /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/explain.out.\n",
      "Executing Connect Reset -- Connect Reset was Successful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the Database.\n",
      "SQL statements have been loaded from sql_statements.json\n",
      "Processing table: ACTIVITYSTMT_ACTEVMON\n",
      "Saved ACTIVITYSTMT_ACTEVMON data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/ACTIVITYSTMT_ACTEVMON.csv\n",
      "Processing table: ACTIVITY_ACTEVMON\n",
      "Saved ACTIVITY_ACTEVMON data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/ACTIVITY_ACTEVMON.csv\n",
      "Processing table: EXPLAIN_ACTUALS\n",
      "Saved EXPLAIN_ACTUALS data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_ACTUALS.csv\n",
      "Processing table: EXPLAIN_INSTANCE\n",
      "Saved EXPLAIN_INSTANCE data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_INSTANCE.csv\n",
      "Processing table: EXPLAIN_OBJECT\n",
      "Saved EXPLAIN_OBJECT data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_OBJECT.csv\n",
      "Processing table: EXPLAIN_OPERATOR\n",
      "Saved EXPLAIN_OPERATOR data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_OPERATOR.csv\n",
      "Processing table: EXPLAIN_PREDICATE\n",
      "Saved EXPLAIN_PREDICATE data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_PREDICATE.csv\n",
      "Processing table: EXPLAIN_STATEMENT\n",
      "Saved EXPLAIN_STATEMENT data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_STATEMENT.csv\n",
      "Processing table: EXPLAIN_STREAM\n",
      "Saved EXPLAIN_STREAM data to /home/db2inst1/db2-labs/explain/batch-queries/output/2025-02-24-18.39.39.920008/EXPLAIN_STREAM.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the subdirectory for a specific explain_time output\n",
    "outputdir = os.path.join(top_level_dir, f\"{explain_time}\")\n",
    "os.makedirs(outputdir, exist_ok=True)  # Create the subdirectory if it doesn't exist\n",
    "\n",
    "# If the directory exists, delete its contents\n",
    "for filename in os.listdir(outputdir):\n",
    "    file_path = os.path.join(outputdir, filename)\n",
    "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)  # Remove files and symlinks\n",
    "    elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)  # Remove subdirectories\n",
    "\n",
    "# Define output file\n",
    "explain_output = \"explain.out\"\n",
    "\n",
    "db2exfmt_cmd = f'''db2exfmt -d \"{database_name}\" -w \"{explain_time}\" -n \"{source_name}\" -s \"{source_schema}\" -# 0 -o \"{outputdir}/{explain_output}\"'''\n",
    "print(db2exfmt_cmd)\n",
    "\n",
    "# Uncomment the following line to execute the command (if running in a shell environment)\n",
    "os.system(db2exfmt_cmd)\n",
    "\n",
    "# Load the dictionary from the JSON file\n",
    "with open(\"export_sql.json\", \"r\") as json_file:\n",
    "    export_sql_statements = json.load(json_file)\n",
    "\n",
    "print(\"SQL statements have been loaded from sql_statements.json\")\n",
    "\n",
    "# Loop through each table in the dictionary\n",
    "for table_name, query in export_sql_statements.items():\n",
    "    print(f\"Processing table: {table_name}\")\n",
    "\n",
    "    # Execute the dynamically generated SQL using %sql magic\n",
    "    df_result = %sql {query}\n",
    "\n",
    "    # Convert result to Pandas DataFrame\n",
    "    # df_result = df_result.DataFrame()\n",
    "\n",
    "    # Save to CSV without including the index in the \"explain\" directory\n",
    "    output_file_path = os.path.join(outputdir, f\"{table_name}.csv\")\n",
    "    df_result.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Saved {table_name} data to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "%sql CONNECT RESET"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
